[INFO|2025-05-14 20:07:25] tokenization_utils_base.py:2058 >> loading file vocab.json

[INFO|2025-05-14 20:07:25] tokenization_utils_base.py:2058 >> loading file merges.txt

[INFO|2025-05-14 20:07:25] tokenization_utils_base.py:2058 >> loading file tokenizer.json

[INFO|2025-05-14 20:07:25] tokenization_utils_base.py:2058 >> loading file added_tokens.json

[INFO|2025-05-14 20:07:25] tokenization_utils_base.py:2058 >> loading file special_tokens_map.json

[INFO|2025-05-14 20:07:25] tokenization_utils_base.py:2058 >> loading file tokenizer_config.json

[INFO|2025-05-14 20:07:25] tokenization_utils_base.py:2058 >> loading file chat_template.jinja

[INFO|2025-05-14 20:07:25] tokenization_utils_base.py:2323 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.

[INFO|2025-05-14 20:07:25] configuration_utils.py:691 >> loading configuration file models/Qwen2_5-1_5b-Instruct/config.json

[INFO|2025-05-14 20:07:25] configuration_utils.py:765 >> Model config Qwen2Config {
  "architectures": [
    "Qwen2ForCausalLM"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151645,
  "hidden_act": "silu",
  "hidden_size": 1536,
  "initializer_range": 0.02,
  "intermediate_size": 8960,
  "max_position_embeddings": 32768,
  "max_window_layers": 21,
  "model_type": "qwen2",
  "num_attention_heads": 12,
  "num_hidden_layers": 28,
  "num_key_value_heads": 2,
  "rms_norm_eps": 1e-06,
  "rope_scaling": null,
  "rope_theta": 1000000.0,
  "sliding_window": 32768,
  "tie_word_embeddings": true,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.51.3",
  "use_cache": true,
  "use_sliding_window": false,
  "vocab_size": 151936
}


[INFO|2025-05-14 20:07:25] tokenization_utils_base.py:2058 >> loading file vocab.json

[INFO|2025-05-14 20:07:25] tokenization_utils_base.py:2058 >> loading file merges.txt

[INFO|2025-05-14 20:07:25] tokenization_utils_base.py:2058 >> loading file tokenizer.json

[INFO|2025-05-14 20:07:25] tokenization_utils_base.py:2058 >> loading file added_tokens.json

[INFO|2025-05-14 20:07:25] tokenization_utils_base.py:2058 >> loading file special_tokens_map.json

[INFO|2025-05-14 20:07:25] tokenization_utils_base.py:2058 >> loading file tokenizer_config.json

[INFO|2025-05-14 20:07:25] tokenization_utils_base.py:2058 >> loading file chat_template.jinja

[INFO|2025-05-14 20:07:25] tokenization_utils_base.py:2323 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.

[INFO|2025-05-14 20:07:25] logging.py:143 >> Loading dataset upper_train.json...

[INFO|2025-05-14 20:07:26] configuration_utils.py:691 >> loading configuration file models/Qwen2_5-1_5b-Instruct/config.json

[INFO|2025-05-14 20:07:26] configuration_utils.py:765 >> Model config Qwen2Config {
  "architectures": [
    "Qwen2ForCausalLM"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151645,
  "hidden_act": "silu",
  "hidden_size": 1536,
  "initializer_range": 0.02,
  "intermediate_size": 8960,
  "max_position_embeddings": 32768,
  "max_window_layers": 21,
  "model_type": "qwen2",
  "num_attention_heads": 12,
  "num_hidden_layers": 28,
  "num_key_value_heads": 2,
  "rms_norm_eps": 1e-06,
  "rope_scaling": null,
  "rope_theta": 1000000.0,
  "sliding_window": 32768,
  "tie_word_embeddings": true,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.51.3",
  "use_cache": true,
  "use_sliding_window": false,
  "vocab_size": 151936
}


[INFO|2025-05-14 20:07:26] logging.py:143 >> KV cache is disabled during training.

[INFO|2025-05-14 20:07:26] modeling_utils.py:1121 >> loading weights file models/Qwen2_5-1_5b-Instruct/model.safetensors

[INFO|2025-05-14 20:07:26] modeling_utils.py:2167 >> Instantiating Qwen2ForCausalLM model under default dtype torch.bfloat16.

[INFO|2025-05-14 20:07:26] configuration_utils.py:1142 >> Generate config GenerationConfig {
  "bos_token_id": 151643,
  "eos_token_id": 151645,
  "use_cache": false
}


[WARNING|2025-05-14 20:07:26] logging.py:328 >> Sliding Window Attention is enabled but not implemented for `eager`; unexpected results may be encountered.

[INFO|2025-05-14 20:07:28] modeling_utils.py:4930 >> All model checkpoint weights were used when initializing Qwen2ForCausalLM.


[INFO|2025-05-14 20:07:28] modeling_utils.py:4938 >> All the weights of Qwen2ForCausalLM were initialized from the model checkpoint at models/Qwen2_5-1_5b-Instruct.
If your task is similar to the task the model of the checkpoint was trained on, you can already use Qwen2ForCausalLM for predictions without further training.

[INFO|2025-05-14 20:07:28] configuration_utils.py:1095 >> loading configuration file models/Qwen2_5-1_5b-Instruct/generation_config.json

[INFO|2025-05-14 20:07:28] configuration_utils.py:1142 >> Generate config GenerationConfig {
  "bos_token_id": 151643,
  "do_sample": true,
  "eos_token_id": [
    151645,
    151643
  ],
  "pad_token_id": 151643,
  "repetition_penalty": 1.1,
  "temperature": 0.7,
  "top_k": 20,
  "top_p": 0.8
}


[INFO|2025-05-14 20:07:28] logging.py:143 >> Gradient checkpointing enabled.

[INFO|2025-05-14 20:07:28] logging.py:143 >> Using vanilla attention implementation.

[INFO|2025-05-14 20:07:28] logging.py:143 >> Upcasting trainable params to float32.

[INFO|2025-05-14 20:07:28] logging.py:143 >> Fine-tuning method: LoRA

[INFO|2025-05-14 20:07:28] logging.py:143 >> Found linear modules: q_proj,gate_proj,o_proj,k_proj,down_proj,up_proj,v_proj

[INFO|2025-05-14 20:07:28] logging.py:143 >> trainable params: 9,232,384 || all params: 1,552,946,688 || trainable%: 0.5945

[INFO|2025-05-14 20:07:28] trainer.py:748 >> Using auto half precision backend

[INFO|2025-05-14 20:07:28] trainer.py:2414 >> ***** Running training *****

[INFO|2025-05-14 20:07:28] trainer.py:2415 >>   Num examples = 1,729

[INFO|2025-05-14 20:07:28] trainer.py:2416 >>   Num Epochs = 20

[INFO|2025-05-14 20:07:28] trainer.py:2417 >>   Instantaneous batch size per device = 2

[INFO|2025-05-14 20:07:28] trainer.py:2420 >>   Total train batch size (w. parallel, distributed & accumulation) = 16

[INFO|2025-05-14 20:07:28] trainer.py:2421 >>   Gradient Accumulation steps = 8

[INFO|2025-05-14 20:07:28] trainer.py:2422 >>   Total optimization steps = 2,160

[INFO|2025-05-14 20:07:28] trainer.py:2423 >>   Number of trainable parameters = 9,232,384

[INFO|2025-05-14 20:07:36] logging.py:143 >> {'loss': 2.0256, 'learning_rate': 5.0000e-05, 'epoch': 0.05, 'throughput': 3173.11}

[INFO|2025-05-14 20:07:42] logging.py:143 >> {'loss': 1.7218, 'learning_rate': 4.9998e-05, 'epoch': 0.09, 'throughput': 3202.15}

[INFO|2025-05-14 20:07:49] logging.py:143 >> {'loss': 1.6433, 'learning_rate': 4.9995e-05, 'epoch': 0.14, 'throughput': 3302.22}

[INFO|2025-05-14 20:07:56] logging.py:143 >> {'loss': 1.5478, 'learning_rate': 4.9990e-05, 'epoch': 0.18, 'throughput': 3315.95}

[INFO|2025-05-14 20:08:03] logging.py:143 >> {'loss': 1.4847, 'learning_rate': 4.9985e-05, 'epoch': 0.23, 'throughput': 3302.86}

[INFO|2025-05-14 20:08:10] logging.py:143 >> {'loss': 1.4776, 'learning_rate': 4.9978e-05, 'epoch': 0.28, 'throughput': 3310.06}

[INFO|2025-05-14 20:08:17] logging.py:143 >> {'loss': 1.4244, 'learning_rate': 4.9969e-05, 'epoch': 0.32, 'throughput': 3314.29}

[INFO|2025-05-14 20:08:24] logging.py:143 >> {'loss': 1.3807, 'learning_rate': 4.9960e-05, 'epoch': 0.37, 'throughput': 3319.02}

[INFO|2025-05-14 20:08:31] logging.py:143 >> {'loss': 1.3530, 'learning_rate': 4.9949e-05, 'epoch': 0.42, 'throughput': 3313.92}

[INFO|2025-05-14 20:08:38] logging.py:143 >> {'loss': 1.2834, 'learning_rate': 4.9937e-05, 'epoch': 0.46, 'throughput': 3320.87}

[INFO|2025-05-14 20:08:45] logging.py:143 >> {'loss': 1.3720, 'learning_rate': 4.9923e-05, 'epoch': 0.51, 'throughput': 3335.00}

[INFO|2025-05-14 20:08:51] logging.py:143 >> {'loss': 1.2788, 'learning_rate': 4.9908e-05, 'epoch': 0.55, 'throughput': 3341.69}

[INFO|2025-05-14 20:08:58] logging.py:143 >> {'loss': 1.3167, 'learning_rate': 4.9892e-05, 'epoch': 0.60, 'throughput': 3341.40}

[INFO|2025-05-14 20:09:05] logging.py:143 >> {'loss': 1.2705, 'learning_rate': 4.9874e-05, 'epoch': 0.65, 'throughput': 3341.92}

[INFO|2025-05-14 20:09:12] logging.py:143 >> {'loss': 1.3127, 'learning_rate': 4.9855e-05, 'epoch': 0.69, 'throughput': 3336.73}

[INFO|2025-05-14 20:09:19] logging.py:143 >> {'loss': 1.3058, 'learning_rate': 4.9835e-05, 'epoch': 0.74, 'throughput': 3339.17}

[INFO|2025-05-14 20:09:26] logging.py:143 >> {'loss': 1.2544, 'learning_rate': 4.9814e-05, 'epoch': 0.79, 'throughput': 3343.63}

[INFO|2025-05-14 20:09:33] logging.py:143 >> {'loss': 1.2402, 'learning_rate': 4.9791e-05, 'epoch': 0.83, 'throughput': 3348.87}

[INFO|2025-05-14 20:09:40] logging.py:143 >> {'loss': 1.2854, 'learning_rate': 4.9767e-05, 'epoch': 0.88, 'throughput': 3354.78}

[INFO|2025-05-14 20:09:47] logging.py:143 >> {'loss': 1.2634, 'learning_rate': 4.9741e-05, 'epoch': 0.92, 'throughput': 3352.44}

[INFO|2025-05-14 20:09:53] logging.py:143 >> {'loss': 1.1801, 'learning_rate': 4.9715e-05, 'epoch': 0.97, 'throughput': 3349.75}

[INFO|2025-05-14 20:09:59] logging.py:143 >> {'loss': 1.3386, 'learning_rate': 4.9686e-05, 'epoch': 1.01, 'throughput': 3344.33}

[INFO|2025-05-14 20:10:06] logging.py:143 >> {'loss': 1.1920, 'learning_rate': 4.9657e-05, 'epoch': 1.06, 'throughput': 3346.45}

[INFO|2025-05-14 20:10:13] logging.py:143 >> {'loss': 1.1050, 'learning_rate': 4.9626e-05, 'epoch': 1.10, 'throughput': 3340.31}

[INFO|2025-05-14 20:10:20] logging.py:143 >> {'loss': 1.1378, 'learning_rate': 4.9595e-05, 'epoch': 1.15, 'throughput': 3344.91}

[INFO|2025-05-14 20:10:27] logging.py:143 >> {'loss': 1.2061, 'learning_rate': 4.9561e-05, 'epoch': 1.19, 'throughput': 3348.60}

[INFO|2025-05-14 20:10:34] logging.py:143 >> {'loss': 1.1188, 'learning_rate': 4.9527e-05, 'epoch': 1.24, 'throughput': 3349.45}

[INFO|2025-05-14 20:10:41] logging.py:143 >> {'loss': 1.1461, 'learning_rate': 4.9491e-05, 'epoch': 1.29, 'throughput': 3354.25}

[INFO|2025-05-14 20:10:47] logging.py:143 >> {'loss': 1.1597, 'learning_rate': 4.9454e-05, 'epoch': 1.33, 'throughput': 3351.57}

[INFO|2025-05-14 20:10:54] logging.py:143 >> {'loss': 1.1913, 'learning_rate': 4.9415e-05, 'epoch': 1.38, 'throughput': 3355.49}

[INFO|2025-05-14 20:11:01] logging.py:143 >> {'loss': 1.1476, 'learning_rate': 4.9376e-05, 'epoch': 1.43, 'throughput': 3355.42}

[INFO|2025-05-14 20:11:08] logging.py:143 >> {'loss': 1.1263, 'learning_rate': 4.9334e-05, 'epoch': 1.47, 'throughput': 3356.04}

[INFO|2025-05-14 20:11:15] logging.py:143 >> {'loss': 1.0812, 'learning_rate': 4.9292e-05, 'epoch': 1.52, 'throughput': 3356.17}

[INFO|2025-05-14 20:11:21] logging.py:143 >> {'loss': 1.0780, 'learning_rate': 4.9249e-05, 'epoch': 1.56, 'throughput': 3355.27}

[INFO|2025-05-14 20:11:28] logging.py:143 >> {'loss': 1.1159, 'learning_rate': 4.9204e-05, 'epoch': 1.61, 'throughput': 3351.21}

[INFO|2025-05-14 20:11:35] logging.py:143 >> {'loss': 1.0895, 'learning_rate': 4.9158e-05, 'epoch': 1.66, 'throughput': 3351.83}

[INFO|2025-05-14 20:11:42] logging.py:143 >> {'loss': 1.0910, 'learning_rate': 4.9110e-05, 'epoch': 1.70, 'throughput': 3352.78}

[INFO|2025-05-14 20:11:49] logging.py:143 >> {'loss': 1.1099, 'learning_rate': 4.9061e-05, 'epoch': 1.75, 'throughput': 3354.57}

[INFO|2025-05-14 20:11:56] logging.py:143 >> {'loss': 1.1099, 'learning_rate': 4.9011e-05, 'epoch': 1.80, 'throughput': 3352.98}

[INFO|2025-05-14 20:12:03] logging.py:143 >> {'loss': 1.1745, 'learning_rate': 4.8960e-05, 'epoch': 1.84, 'throughput': 3355.27}

[INFO|2025-05-14 20:12:10] logging.py:143 >> {'loss': 1.1051, 'learning_rate': 4.8908e-05, 'epoch': 1.89, 'throughput': 3355.39}

[INFO|2025-05-14 20:12:16] logging.py:143 >> {'loss': 1.0619, 'learning_rate': 4.8854e-05, 'epoch': 1.93, 'throughput': 3356.73}

[INFO|2025-05-14 20:12:23] logging.py:143 >> {'loss': 1.1224, 'learning_rate': 4.8799e-05, 'epoch': 1.98, 'throughput': 3352.52}

[INFO|2025-05-14 20:12:29] logging.py:143 >> {'loss': 1.0493, 'learning_rate': 4.8742e-05, 'epoch': 2.02, 'throughput': 3350.28}

[INFO|2025-05-14 20:12:36] logging.py:143 >> {'loss': 1.0551, 'learning_rate': 4.8685e-05, 'epoch': 2.06, 'throughput': 3349.62}

[INFO|2025-05-14 20:12:43] logging.py:143 >> {'loss': 1.0328, 'learning_rate': 4.8626e-05, 'epoch': 2.11, 'throughput': 3351.31}

[INFO|2025-05-14 20:12:50] logging.py:143 >> {'loss': 1.0560, 'learning_rate': 4.8566e-05, 'epoch': 2.16, 'throughput': 3353.35}

[INFO|2025-05-14 20:12:56] logging.py:143 >> {'loss': 0.9788, 'learning_rate': 4.8505e-05, 'epoch': 2.20, 'throughput': 3352.44}

[INFO|2025-05-14 20:13:03] logging.py:143 >> {'loss': 1.0476, 'learning_rate': 4.8442e-05, 'epoch': 2.25, 'throughput': 3353.76}

[INFO|2025-05-14 20:13:10] logging.py:143 >> {'loss': 1.0182, 'learning_rate': 4.8378e-05, 'epoch': 2.30, 'throughput': 3355.74}

[INFO|2025-05-14 20:13:17] logging.py:143 >> {'loss': 1.0332, 'learning_rate': 4.8313e-05, 'epoch': 2.34, 'throughput': 3355.59}

[INFO|2025-05-14 20:13:24] logging.py:143 >> {'loss': 1.0278, 'learning_rate': 4.8247e-05, 'epoch': 2.39, 'throughput': 3357.08}

[INFO|2025-05-14 20:13:31] logging.py:143 >> {'loss': 0.9931, 'learning_rate': 4.8180e-05, 'epoch': 2.43, 'throughput': 3358.28}

[INFO|2025-05-14 20:13:37] logging.py:143 >> {'loss': 1.0403, 'learning_rate': 4.8111e-05, 'epoch': 2.48, 'throughput': 3358.99}

[INFO|2025-05-14 20:13:44] logging.py:143 >> {'loss': 0.9665, 'learning_rate': 4.8041e-05, 'epoch': 2.53, 'throughput': 3359.05}

[INFO|2025-05-14 20:13:51] logging.py:143 >> {'loss': 0.9574, 'learning_rate': 4.7970e-05, 'epoch': 2.57, 'throughput': 3357.88}

[INFO|2025-05-14 20:13:58] logging.py:143 >> {'loss': 1.0512, 'learning_rate': 4.7897e-05, 'epoch': 2.62, 'throughput': 3357.91}

[INFO|2025-05-14 20:14:05] logging.py:143 >> {'loss': 1.0084, 'learning_rate': 4.7824e-05, 'epoch': 2.67, 'throughput': 3358.10}

[INFO|2025-05-14 20:14:12] logging.py:143 >> {'loss': 1.0129, 'learning_rate': 4.7749e-05, 'epoch': 2.71, 'throughput': 3357.56}

[INFO|2025-05-14 20:14:19] logging.py:143 >> {'loss': 1.0030, 'learning_rate': 4.7673e-05, 'epoch': 2.76, 'throughput': 3353.99}

[INFO|2025-05-14 20:14:26] logging.py:143 >> {'loss': 1.0269, 'learning_rate': 4.7596e-05, 'epoch': 2.80, 'throughput': 3350.44}

[INFO|2025-05-14 20:14:33] logging.py:143 >> {'loss': 0.9624, 'learning_rate': 4.7517e-05, 'epoch': 2.85, 'throughput': 3349.30}

[INFO|2025-05-14 20:14:40] logging.py:143 >> {'loss': 1.0524, 'learning_rate': 4.7438e-05, 'epoch': 2.90, 'throughput': 3349.28}

[INFO|2025-05-14 20:14:48] logging.py:143 >> {'loss': 0.9959, 'learning_rate': 4.7357e-05, 'epoch': 2.94, 'throughput': 3346.46}

[INFO|2025-05-14 20:14:55] logging.py:143 >> {'loss': 0.9895, 'learning_rate': 4.7275e-05, 'epoch': 2.99, 'throughput': 3342.16}

[INFO|2025-05-14 20:15:01] logging.py:143 >> {'loss': 0.9910, 'learning_rate': 4.7192e-05, 'epoch': 3.03, 'throughput': 3341.39}

[INFO|2025-05-14 20:15:08] logging.py:143 >> {'loss': 0.9236, 'learning_rate': 4.7108e-05, 'epoch': 3.07, 'throughput': 3339.13}

[INFO|2025-05-14 20:15:15] logging.py:143 >> {'loss': 0.9456, 'learning_rate': 4.7022e-05, 'epoch': 3.12, 'throughput': 3340.23}

[INFO|2025-05-14 20:15:22] logging.py:143 >> {'loss': 0.9505, 'learning_rate': 4.6936e-05, 'epoch': 3.17, 'throughput': 3339.87}

[INFO|2025-05-14 20:15:29] logging.py:143 >> {'loss': 0.9676, 'learning_rate': 4.6848e-05, 'epoch': 3.21, 'throughput': 3340.23}

[INFO|2025-05-14 20:15:36] logging.py:143 >> {'loss': 0.8945, 'learning_rate': 4.6759e-05, 'epoch': 3.26, 'throughput': 3338.55}

[INFO|2025-05-14 20:15:43] logging.py:143 >> {'loss': 0.9521, 'learning_rate': 4.6669e-05, 'epoch': 3.31, 'throughput': 3338.10}

[INFO|2025-05-14 20:15:50] logging.py:143 >> {'loss': 0.9632, 'learning_rate': 4.6578e-05, 'epoch': 3.35, 'throughput': 3338.07}

[INFO|2025-05-14 20:15:57] logging.py:143 >> {'loss': 0.9178, 'learning_rate': 4.6485e-05, 'epoch': 3.40, 'throughput': 3338.64}

[INFO|2025-05-14 20:16:04] logging.py:143 >> {'loss': 0.9061, 'learning_rate': 4.6392e-05, 'epoch': 3.44, 'throughput': 3337.03}

[INFO|2025-05-14 20:16:11] logging.py:143 >> {'loss': 0.9603, 'learning_rate': 4.6297e-05, 'epoch': 3.49, 'throughput': 3337.49}

[INFO|2025-05-14 20:16:18] logging.py:143 >> {'loss': 0.8936, 'learning_rate': 4.6201e-05, 'epoch': 3.54, 'throughput': 3337.93}

[INFO|2025-05-14 20:16:25] logging.py:143 >> {'loss': 0.8716, 'learning_rate': 4.6104e-05, 'epoch': 3.58, 'throughput': 3337.90}

[INFO|2025-05-14 20:16:32] logging.py:143 >> {'loss': 0.9259, 'learning_rate': 4.6006e-05, 'epoch': 3.63, 'throughput': 3338.04}

[INFO|2025-05-14 20:16:39] logging.py:143 >> {'loss': 0.9331, 'learning_rate': 4.5907e-05, 'epoch': 3.68, 'throughput': 3338.08}

[INFO|2025-05-14 20:16:45] logging.py:143 >> {'loss': 0.9134, 'learning_rate': 4.5807e-05, 'epoch': 3.72, 'throughput': 3338.68}

[INFO|2025-05-14 20:16:52] logging.py:143 >> {'loss': 0.8906, 'learning_rate': 4.5706e-05, 'epoch': 3.77, 'throughput': 3339.06}

[INFO|2025-05-14 20:16:59] logging.py:143 >> {'loss': 0.8950, 'learning_rate': 4.5603e-05, 'epoch': 3.81, 'throughput': 3338.80}

[INFO|2025-05-14 20:17:06] logging.py:143 >> {'loss': 0.8998, 'learning_rate': 4.5500e-05, 'epoch': 3.86, 'throughput': 3338.40}

[INFO|2025-05-14 20:17:13] logging.py:143 >> {'loss': 0.8713, 'learning_rate': 4.5395e-05, 'epoch': 3.91, 'throughput': 3336.61}

[INFO|2025-05-14 20:17:20] logging.py:143 >> {'loss': 0.9729, 'learning_rate': 4.5289e-05, 'epoch': 3.95, 'throughput': 3335.10}

[INFO|2025-05-14 20:17:27] logging.py:143 >> {'loss': 0.9406, 'learning_rate': 4.5183e-05, 'epoch': 4.00, 'throughput': 3334.90}

[INFO|2025-05-14 20:17:33] logging.py:143 >> {'loss': 0.8608, 'learning_rate': 4.5075e-05, 'epoch': 4.04, 'throughput': 3334.51}

[INFO|2025-05-14 20:17:40] logging.py:143 >> {'loss': 0.8520, 'learning_rate': 4.4966e-05, 'epoch': 4.08, 'throughput': 3333.66}

[INFO|2025-05-14 20:17:47] logging.py:143 >> {'loss': 0.7917, 'learning_rate': 4.4856e-05, 'epoch': 4.13, 'throughput': 3331.98}

[INFO|2025-05-14 20:17:53] logging.py:143 >> {'loss': 0.9425, 'learning_rate': 4.4745e-05, 'epoch': 4.18, 'throughput': 3334.04}

[INFO|2025-05-14 20:18:00] logging.py:143 >> {'loss': 0.8625, 'learning_rate': 4.4633e-05, 'epoch': 4.22, 'throughput': 3334.82}

[INFO|2025-05-14 20:18:07] logging.py:143 >> {'loss': 0.8066, 'learning_rate': 4.4520e-05, 'epoch': 4.27, 'throughput': 3334.91}

[INFO|2025-05-14 20:18:14] logging.py:143 >> {'loss': 0.8326, 'learning_rate': 4.4406e-05, 'epoch': 4.31, 'throughput': 3334.00}

[INFO|2025-05-14 20:18:21] logging.py:143 >> {'loss': 0.7916, 'learning_rate': 4.4291e-05, 'epoch': 4.36, 'throughput': 3333.11}

[INFO|2025-05-14 20:18:28] logging.py:143 >> {'loss': 0.8379, 'learning_rate': 4.4174e-05, 'epoch': 4.41, 'throughput': 3332.12}

[INFO|2025-05-14 20:18:35] logging.py:143 >> {'loss': 0.8778, 'learning_rate': 4.4057e-05, 'epoch': 4.45, 'throughput': 3331.96}

[INFO|2025-05-14 20:18:42] logging.py:143 >> {'loss': 0.9039, 'learning_rate': 4.3939e-05, 'epoch': 4.50, 'throughput': 3332.45}

[INFO|2025-05-14 20:18:49] logging.py:143 >> {'loss': 0.8378, 'learning_rate': 4.3820e-05, 'epoch': 4.55, 'throughput': 3332.07}

[INFO|2025-05-14 20:18:56] logging.py:143 >> {'loss': 0.7951, 'learning_rate': 4.3700e-05, 'epoch': 4.59, 'throughput': 3331.46}

[INFO|2025-05-14 20:19:03] logging.py:143 >> {'loss': 0.8456, 'learning_rate': 4.3579e-05, 'epoch': 4.64, 'throughput': 3331.27}

[INFO|2025-05-14 20:19:10] logging.py:143 >> {'loss': 0.8523, 'learning_rate': 4.3456e-05, 'epoch': 4.68, 'throughput': 3332.44}

[INFO|2025-05-14 20:19:17] logging.py:143 >> {'loss': 0.7998, 'learning_rate': 4.3333e-05, 'epoch': 4.73, 'throughput': 3331.86}

[INFO|2025-05-14 20:19:24] logging.py:143 >> {'loss': 0.8168, 'learning_rate': 4.3209e-05, 'epoch': 4.78, 'throughput': 3331.79}

[INFO|2025-05-14 20:19:31] logging.py:143 >> {'loss': 0.8590, 'learning_rate': 4.3084e-05, 'epoch': 4.82, 'throughput': 3331.56}

[INFO|2025-05-14 20:19:38] logging.py:143 >> {'loss': 0.9235, 'learning_rate': 4.2958e-05, 'epoch': 4.87, 'throughput': 3331.32}

[INFO|2025-05-14 20:19:45] logging.py:143 >> {'loss': 0.8507, 'learning_rate': 4.2831e-05, 'epoch': 4.92, 'throughput': 3331.38}

[INFO|2025-05-14 20:19:52] logging.py:143 >> {'loss': 0.8481, 'learning_rate': 4.2703e-05, 'epoch': 4.96, 'throughput': 3331.79}

[INFO|2025-05-14 20:19:57] logging.py:143 >> {'loss': 0.8247, 'learning_rate': 4.2575e-05, 'epoch': 5.00, 'throughput': 3330.66}

[INFO|2025-05-14 20:20:04] logging.py:143 >> {'loss': 0.7749, 'learning_rate': 4.2445e-05, 'epoch': 5.05, 'throughput': 3329.70}

[INFO|2025-05-14 20:20:11] logging.py:143 >> {'loss': 0.7894, 'learning_rate': 4.2314e-05, 'epoch': 5.09, 'throughput': 3329.63}

[INFO|2025-05-14 20:20:18] logging.py:143 >> {'loss': 0.7388, 'learning_rate': 4.2182e-05, 'epoch': 5.14, 'throughput': 3329.23}

[INFO|2025-05-14 20:20:25] logging.py:143 >> {'loss': 0.7622, 'learning_rate': 4.2050e-05, 'epoch': 5.18, 'throughput': 3329.63}

[INFO|2025-05-14 20:20:32] logging.py:143 >> {'loss': 0.7814, 'learning_rate': 4.1917e-05, 'epoch': 5.23, 'throughput': 3329.60}

[INFO|2025-05-14 20:20:39] logging.py:143 >> {'loss': 0.7501, 'learning_rate': 4.1782e-05, 'epoch': 5.28, 'throughput': 3330.19}

[INFO|2025-05-14 20:20:46] logging.py:143 >> {'loss': 0.7446, 'learning_rate': 4.1647e-05, 'epoch': 5.32, 'throughput': 3330.63}

[INFO|2025-05-14 20:20:52] logging.py:143 >> {'loss': 0.7818, 'learning_rate': 4.1511e-05, 'epoch': 5.37, 'throughput': 3330.30}

[INFO|2025-05-14 20:20:59] logging.py:143 >> {'loss': 0.7522, 'learning_rate': 4.1374e-05, 'epoch': 5.42, 'throughput': 3329.96}

[INFO|2025-05-14 20:21:06] logging.py:143 >> {'loss': 0.8137, 'learning_rate': 4.1236e-05, 'epoch': 5.46, 'throughput': 3330.85}

[INFO|2025-05-14 20:21:13] logging.py:143 >> {'loss': 0.8019, 'learning_rate': 4.1098e-05, 'epoch': 5.51, 'throughput': 3332.23}

[INFO|2025-05-14 20:21:20] logging.py:143 >> {'loss': 0.7797, 'learning_rate': 4.0958e-05, 'epoch': 5.55, 'throughput': 3331.72}

[INFO|2025-05-14 20:21:27] logging.py:143 >> {'loss': 0.7907, 'learning_rate': 4.0818e-05, 'epoch': 5.60, 'throughput': 3332.54}

[INFO|2025-05-14 20:21:34] logging.py:143 >> {'loss': 0.7530, 'learning_rate': 4.0676e-05, 'epoch': 5.65, 'throughput': 3333.34}

[INFO|2025-05-14 20:21:41] logging.py:143 >> {'loss': 0.7437, 'learning_rate': 4.0534e-05, 'epoch': 5.69, 'throughput': 3333.18}

[INFO|2025-05-14 20:21:47] logging.py:143 >> {'loss': 0.7528, 'learning_rate': 4.0392e-05, 'epoch': 5.74, 'throughput': 3333.68}

[INFO|2025-05-14 20:21:54] logging.py:143 >> {'loss': 0.7580, 'learning_rate': 4.0248e-05, 'epoch': 5.79, 'throughput': 3334.81}

[INFO|2025-05-14 20:22:01] logging.py:143 >> {'loss': 0.8059, 'learning_rate': 4.0103e-05, 'epoch': 5.83, 'throughput': 3334.45}

[INFO|2025-05-14 20:22:08] logging.py:143 >> {'loss': 0.7917, 'learning_rate': 3.9958e-05, 'epoch': 5.88, 'throughput': 3334.62}

[INFO|2025-05-14 20:22:15] logging.py:143 >> {'loss': 0.7867, 'learning_rate': 3.9812e-05, 'epoch': 5.92, 'throughput': 3333.53}

[INFO|2025-05-14 20:22:22] logging.py:143 >> {'loss': 0.7783, 'learning_rate': 3.9665e-05, 'epoch': 5.97, 'throughput': 3333.28}

[INFO|2025-05-14 20:22:28] logging.py:143 >> {'loss': 0.7953, 'learning_rate': 3.9518e-05, 'epoch': 6.01, 'throughput': 3332.35}

[INFO|2025-05-14 20:22:35] logging.py:143 >> {'loss': 0.6915, 'learning_rate': 3.9369e-05, 'epoch': 6.06, 'throughput': 3332.35}

[INFO|2025-05-14 20:22:42] logging.py:143 >> {'loss': 0.6993, 'learning_rate': 3.9220e-05, 'epoch': 6.10, 'throughput': 3332.52}

[INFO|2025-05-14 20:22:48] logging.py:143 >> {'loss': 0.6952, 'learning_rate': 3.9070e-05, 'epoch': 6.15, 'throughput': 3332.80}

[INFO|2025-05-14 20:22:55] logging.py:143 >> {'loss': 0.6275, 'learning_rate': 3.8919e-05, 'epoch': 6.19, 'throughput': 3332.78}

[INFO|2025-05-14 20:23:02] logging.py:143 >> {'loss': 0.7453, 'learning_rate': 3.8768e-05, 'epoch': 6.24, 'throughput': 3333.16}

[INFO|2025-05-14 20:23:09] logging.py:143 >> {'loss': 0.7004, 'learning_rate': 3.8616e-05, 'epoch': 6.29, 'throughput': 3333.11}

[INFO|2025-05-14 20:23:16] logging.py:143 >> {'loss': 0.6862, 'learning_rate': 3.8463e-05, 'epoch': 6.33, 'throughput': 3332.74}

[INFO|2025-05-14 20:23:23] logging.py:143 >> {'loss': 0.7067, 'learning_rate': 3.8310e-05, 'epoch': 6.38, 'throughput': 3332.04}

[INFO|2025-05-14 20:23:30] logging.py:143 >> {'loss': 0.7537, 'learning_rate': 3.8155e-05, 'epoch': 6.43, 'throughput': 3333.06}

[INFO|2025-05-14 20:23:37] logging.py:143 >> {'loss': 0.7124, 'learning_rate': 3.8000e-05, 'epoch': 6.47, 'throughput': 3332.47}

[INFO|2025-05-14 20:23:44] logging.py:143 >> {'loss': 0.6755, 'learning_rate': 3.7845e-05, 'epoch': 6.52, 'throughput': 3331.71}

[INFO|2025-05-14 20:23:51] logging.py:143 >> {'loss': 0.7287, 'learning_rate': 3.7688e-05, 'epoch': 6.56, 'throughput': 3331.58}

[INFO|2025-05-14 20:23:58] logging.py:143 >> {'loss': 0.6940, 'learning_rate': 3.7531e-05, 'epoch': 6.61, 'throughput': 3331.64}

[INFO|2025-05-14 20:24:05] logging.py:143 >> {'loss': 0.6617, 'learning_rate': 3.7374e-05, 'epoch': 6.66, 'throughput': 3332.11}

[INFO|2025-05-14 20:24:12] logging.py:143 >> {'loss': 0.6868, 'learning_rate': 3.7216e-05, 'epoch': 6.70, 'throughput': 3331.13}

[INFO|2025-05-14 20:24:19] logging.py:143 >> {'loss': 0.6869, 'learning_rate': 3.7057e-05, 'epoch': 6.75, 'throughput': 3331.47}

[INFO|2025-05-14 20:24:26] logging.py:143 >> {'loss': 0.6697, 'learning_rate': 3.6897e-05, 'epoch': 6.80, 'throughput': 3332.03}

[INFO|2025-05-14 20:24:33] logging.py:143 >> {'loss': 0.7084, 'learning_rate': 3.6737e-05, 'epoch': 6.84, 'throughput': 3332.14}

[INFO|2025-05-14 20:24:39] logging.py:143 >> {'loss': 0.6941, 'learning_rate': 3.6576e-05, 'epoch': 6.89, 'throughput': 3331.88}

[INFO|2025-05-14 20:24:46] logging.py:143 >> {'loss': 0.7172, 'learning_rate': 3.6415e-05, 'epoch': 6.93, 'throughput': 3331.16}

[INFO|2025-05-14 20:24:53] logging.py:143 >> {'loss': 0.7125, 'learning_rate': 3.6252e-05, 'epoch': 6.98, 'throughput': 3331.77}

[INFO|2025-05-14 20:24:59] logging.py:143 >> {'loss': 0.7109, 'learning_rate': 3.6090e-05, 'epoch': 7.02, 'throughput': 3332.42}

[INFO|2025-05-14 20:25:06] logging.py:143 >> {'loss': 0.6344, 'learning_rate': 3.5927e-05, 'epoch': 7.06, 'throughput': 3332.47}

[INFO|2025-05-14 20:25:13] logging.py:143 >> {'loss': 0.6304, 'learning_rate': 3.5763e-05, 'epoch': 7.11, 'throughput': 3332.63}

[INFO|2025-05-14 20:25:19] logging.py:143 >> {'loss': 0.5751, 'learning_rate': 3.5598e-05, 'epoch': 7.16, 'throughput': 3332.58}

[INFO|2025-05-14 20:25:26] logging.py:143 >> {'loss': 0.5838, 'learning_rate': 3.5433e-05, 'epoch': 7.20, 'throughput': 3333.39}

[INFO|2025-05-14 20:25:33] logging.py:143 >> {'loss': 0.6389, 'learning_rate': 3.5268e-05, 'epoch': 7.25, 'throughput': 3333.01}

[INFO|2025-05-14 20:25:40] logging.py:143 >> {'loss': 0.6427, 'learning_rate': 3.5102e-05, 'epoch': 7.30, 'throughput': 3332.47}

[INFO|2025-05-14 20:25:47] logging.py:143 >> {'loss': 0.6093, 'learning_rate': 3.4935e-05, 'epoch': 7.34, 'throughput': 3332.81}

[INFO|2025-05-14 20:25:54] logging.py:143 >> {'loss': 0.6428, 'learning_rate': 3.4768e-05, 'epoch': 7.39, 'throughput': 3333.27}

[INFO|2025-05-14 20:26:01] logging.py:143 >> {'loss': 0.6140, 'learning_rate': 3.4601e-05, 'epoch': 7.43, 'throughput': 3332.52}

[INFO|2025-05-14 20:26:08] logging.py:143 >> {'loss': 0.6293, 'learning_rate': 3.4433e-05, 'epoch': 7.48, 'throughput': 3332.73}

[INFO|2025-05-14 20:26:14] logging.py:143 >> {'loss': 0.6141, 'learning_rate': 3.4264e-05, 'epoch': 7.53, 'throughput': 3333.42}

[INFO|2025-05-14 20:26:21] logging.py:143 >> {'loss': 0.6321, 'learning_rate': 3.4095e-05, 'epoch': 7.57, 'throughput': 3333.78}

[INFO|2025-05-14 20:26:28] logging.py:143 >> {'loss': 0.6324, 'learning_rate': 3.3925e-05, 'epoch': 7.62, 'throughput': 3333.78}

[INFO|2025-05-14 20:26:35] logging.py:143 >> {'loss': 0.6583, 'learning_rate': 3.3755e-05, 'epoch': 7.67, 'throughput': 3333.66}

[INFO|2025-05-14 20:26:42] logging.py:143 >> {'loss': 0.6735, 'learning_rate': 3.3585e-05, 'epoch': 7.71, 'throughput': 3334.23}

[INFO|2025-05-14 20:26:49] logging.py:143 >> {'loss': 0.6236, 'learning_rate': 3.3414e-05, 'epoch': 7.76, 'throughput': 3333.97}

[INFO|2025-05-14 20:26:56] logging.py:143 >> {'loss': 0.6654, 'learning_rate': 3.3242e-05, 'epoch': 7.80, 'throughput': 3334.72}

[INFO|2025-05-14 20:27:03] logging.py:143 >> {'loss': 0.6592, 'learning_rate': 3.3070e-05, 'epoch': 7.85, 'throughput': 3334.71}

[INFO|2025-05-14 20:27:10] logging.py:143 >> {'loss': 0.6415, 'learning_rate': 3.2898e-05, 'epoch': 7.90, 'throughput': 3335.22}

[INFO|2025-05-14 20:27:16] logging.py:143 >> {'loss': 0.6432, 'learning_rate': 3.2725e-05, 'epoch': 7.94, 'throughput': 3334.66}

[INFO|2025-05-14 20:27:23] logging.py:143 >> {'loss': 0.6463, 'learning_rate': 3.2552e-05, 'epoch': 7.99, 'throughput': 3335.55}

[INFO|2025-05-14 20:27:29] logging.py:143 >> {'loss': 0.6105, 'learning_rate': 3.2379e-05, 'epoch': 8.03, 'throughput': 3335.55}

[INFO|2025-05-14 20:27:36] logging.py:143 >> {'loss': 0.5570, 'learning_rate': 3.2205e-05, 'epoch': 8.07, 'throughput': 3335.39}

[INFO|2025-05-14 20:27:43] logging.py:143 >> {'loss': 0.5589, 'learning_rate': 3.2031e-05, 'epoch': 8.12, 'throughput': 3335.81}

[INFO|2025-05-14 20:27:49] logging.py:143 >> {'loss': 0.5500, 'learning_rate': 3.1856e-05, 'epoch': 8.17, 'throughput': 3335.97}

[INFO|2025-05-14 20:27:56] logging.py:143 >> {'loss': 0.5659, 'learning_rate': 3.1681e-05, 'epoch': 8.21, 'throughput': 3336.50}

[INFO|2025-05-14 20:28:03] logging.py:143 >> {'loss': 0.5622, 'learning_rate': 3.1506e-05, 'epoch': 8.26, 'throughput': 3336.91}

[INFO|2025-05-14 20:28:10] logging.py:143 >> {'loss': 0.5546, 'learning_rate': 3.1330e-05, 'epoch': 8.31, 'throughput': 3336.98}

[INFO|2025-05-14 20:28:17] logging.py:143 >> {'loss': 0.5682, 'learning_rate': 3.1154e-05, 'epoch': 8.35, 'throughput': 3337.00}

[INFO|2025-05-14 20:28:24] logging.py:143 >> {'loss': 0.5678, 'learning_rate': 3.0977e-05, 'epoch': 8.40, 'throughput': 3337.69}

[INFO|2025-05-14 20:28:31] logging.py:143 >> {'loss': 0.5824, 'learning_rate': 3.0801e-05, 'epoch': 8.44, 'throughput': 3337.49}

[INFO|2025-05-14 20:28:38] logging.py:143 >> {'loss': 0.5767, 'learning_rate': 3.0624e-05, 'epoch': 8.49, 'throughput': 3337.62}

[INFO|2025-05-14 20:28:44] logging.py:143 >> {'loss': 0.5614, 'learning_rate': 3.0446e-05, 'epoch': 8.54, 'throughput': 3337.35}

[INFO|2025-05-14 20:28:51] logging.py:143 >> {'loss': 0.5799, 'learning_rate': 3.0269e-05, 'epoch': 8.58, 'throughput': 3337.75}

[INFO|2025-05-14 20:28:58] logging.py:143 >> {'loss': 0.5876, 'learning_rate': 3.0091e-05, 'epoch': 8.63, 'throughput': 3338.22}

[INFO|2025-05-14 20:29:05] logging.py:143 >> {'loss': 0.5632, 'learning_rate': 2.9913e-05, 'epoch': 8.68, 'throughput': 3338.59}

[INFO|2025-05-14 20:29:12] logging.py:143 >> {'loss': 0.5504, 'learning_rate': 2.9735e-05, 'epoch': 8.72, 'throughput': 3338.07}

[INFO|2025-05-14 20:29:19] logging.py:143 >> {'loss': 0.5715, 'learning_rate': 2.9556e-05, 'epoch': 8.77, 'throughput': 3338.36}

[INFO|2025-05-14 20:29:26] logging.py:143 >> {'loss': 0.5508, 'learning_rate': 2.9377e-05, 'epoch': 8.81, 'throughput': 3338.41}

[INFO|2025-05-14 20:29:33] logging.py:143 >> {'loss': 0.5559, 'learning_rate': 2.9198e-05, 'epoch': 8.86, 'throughput': 3337.36}

[INFO|2025-05-14 20:29:40] logging.py:143 >> {'loss': 0.5527, 'learning_rate': 2.9019e-05, 'epoch': 8.91, 'throughput': 3336.53}

[INFO|2025-05-14 20:29:47] logging.py:143 >> {'loss': 0.5957, 'learning_rate': 2.8839e-05, 'epoch': 8.95, 'throughput': 3336.97}

[INFO|2025-05-14 20:29:54] logging.py:143 >> {'loss': 0.5860, 'learning_rate': 2.8659e-05, 'epoch': 9.00, 'throughput': 3337.09}

[INFO|2025-05-14 20:29:59] logging.py:143 >> {'loss': 0.5061, 'learning_rate': 2.8479e-05, 'epoch': 9.04, 'throughput': 3336.95}

[INFO|2025-05-14 20:30:06] logging.py:143 >> {'loss': 0.4878, 'learning_rate': 2.8299e-05, 'epoch': 9.08, 'throughput': 3337.75}

[INFO|2025-05-14 20:30:13] logging.py:143 >> {'loss': 0.4929, 'learning_rate': 2.8119e-05, 'epoch': 9.13, 'throughput': 3337.49}

[INFO|2025-05-14 20:30:20] logging.py:143 >> {'loss': 0.4847, 'learning_rate': 2.7938e-05, 'epoch': 9.18, 'throughput': 3337.92}

[INFO|2025-05-14 20:30:27] logging.py:143 >> {'loss': 0.4904, 'learning_rate': 2.7758e-05, 'epoch': 9.22, 'throughput': 3338.05}

[INFO|2025-05-14 20:30:34] logging.py:143 >> {'loss': 0.4905, 'learning_rate': 2.7577e-05, 'epoch': 9.27, 'throughput': 3337.98}

[INFO|2025-05-14 20:30:41] logging.py:143 >> {'loss': 0.4904, 'learning_rate': 2.7396e-05, 'epoch': 9.31, 'throughput': 3337.95}

[INFO|2025-05-14 20:30:48] logging.py:143 >> {'loss': 0.4806, 'learning_rate': 2.7215e-05, 'epoch': 9.36, 'throughput': 3337.69}

[INFO|2025-05-14 20:30:54] logging.py:143 >> {'loss': 0.5051, 'learning_rate': 2.7034e-05, 'epoch': 9.41, 'throughput': 3337.27}

[INFO|2025-05-14 20:31:01] logging.py:143 >> {'loss': 0.5056, 'learning_rate': 2.6853e-05, 'epoch': 9.45, 'throughput': 3337.32}

[INFO|2025-05-14 20:31:08] logging.py:143 >> {'loss': 0.5327, 'learning_rate': 2.6671e-05, 'epoch': 9.50, 'throughput': 3336.98}

[INFO|2025-05-14 20:31:15] logging.py:143 >> {'loss': 0.5417, 'learning_rate': 2.6490e-05, 'epoch': 9.55, 'throughput': 3337.43}

[INFO|2025-05-14 20:31:22] logging.py:143 >> {'loss': 0.5118, 'learning_rate': 2.6308e-05, 'epoch': 9.59, 'throughput': 3337.66}

[INFO|2025-05-14 20:31:29] logging.py:143 >> {'loss': 0.5048, 'learning_rate': 2.6127e-05, 'epoch': 9.64, 'throughput': 3338.08}

[INFO|2025-05-14 20:31:36] logging.py:143 >> {'loss': 0.5360, 'learning_rate': 2.5945e-05, 'epoch': 9.68, 'throughput': 3338.44}

[INFO|2025-05-14 20:31:43] logging.py:143 >> {'loss': 0.5204, 'learning_rate': 2.5763e-05, 'epoch': 9.73, 'throughput': 3338.41}

[INFO|2025-05-14 20:31:49] logging.py:143 >> {'loss': 0.4898, 'learning_rate': 2.5582e-05, 'epoch': 9.78, 'throughput': 3338.36}

[INFO|2025-05-14 20:31:56] logging.py:143 >> {'loss': 0.4948, 'learning_rate': 2.5400e-05, 'epoch': 9.82, 'throughput': 3338.63}

[INFO|2025-05-14 20:32:03] logging.py:143 >> {'loss': 0.5530, 'learning_rate': 2.5218e-05, 'epoch': 9.87, 'throughput': 3338.88}

[INFO|2025-05-14 20:32:10] logging.py:143 >> {'loss': 0.4887, 'learning_rate': 2.5036e-05, 'epoch': 9.92, 'throughput': 3338.92}

[INFO|2025-05-14 20:32:17] logging.py:143 >> {'loss': 0.5376, 'learning_rate': 2.4855e-05, 'epoch': 9.96, 'throughput': 3338.78}

[INFO|2025-05-14 20:32:23] logging.py:143 >> {'loss': 0.4985, 'learning_rate': 2.4673e-05, 'epoch': 10.00, 'throughput': 3338.79}

[INFO|2025-05-14 20:32:29] logging.py:143 >> {'loss': 0.4492, 'learning_rate': 2.4491e-05, 'epoch': 10.05, 'throughput': 3338.86}

[INFO|2025-05-14 20:32:36] logging.py:143 >> {'loss': 0.4240, 'learning_rate': 2.4309e-05, 'epoch': 10.09, 'throughput': 3338.51}

[INFO|2025-05-14 20:32:43] logging.py:143 >> {'loss': 0.4641, 'learning_rate': 2.4128e-05, 'epoch': 10.14, 'throughput': 3338.64}

[INFO|2025-05-14 20:32:50] logging.py:143 >> {'loss': 0.4776, 'learning_rate': 2.3946e-05, 'epoch': 10.18, 'throughput': 3339.13}

[INFO|2025-05-14 20:32:57] logging.py:143 >> {'loss': 0.4598, 'learning_rate': 2.3764e-05, 'epoch': 10.23, 'throughput': 3338.78}

[INFO|2025-05-14 20:33:04] logging.py:143 >> {'loss': 0.4651, 'learning_rate': 2.3583e-05, 'epoch': 10.28, 'throughput': 3338.60}

[INFO|2025-05-14 20:33:11] logging.py:143 >> {'loss': 0.4709, 'learning_rate': 2.3401e-05, 'epoch': 10.32, 'throughput': 3338.67}

[INFO|2025-05-14 20:33:18] logging.py:143 >> {'loss': 0.4603, 'learning_rate': 2.3220e-05, 'epoch': 10.37, 'throughput': 3338.80}

[INFO|2025-05-14 20:33:25] logging.py:143 >> {'loss': 0.4518, 'learning_rate': 2.3039e-05, 'epoch': 10.42, 'throughput': 3339.70}

[INFO|2025-05-14 20:33:32] logging.py:143 >> {'loss': 0.4222, 'learning_rate': 2.2857e-05, 'epoch': 10.46, 'throughput': 3340.05}

[INFO|2025-05-14 20:33:39] logging.py:143 >> {'loss': 0.4699, 'learning_rate': 2.2676e-05, 'epoch': 10.51, 'throughput': 3339.58}

[INFO|2025-05-14 20:33:46] logging.py:143 >> {'loss': 0.4601, 'learning_rate': 2.2495e-05, 'epoch': 10.55, 'throughput': 3339.55}

[INFO|2025-05-14 20:33:53] logging.py:143 >> {'loss': 0.4672, 'learning_rate': 2.2314e-05, 'epoch': 10.60, 'throughput': 3339.31}

[INFO|2025-05-14 20:33:59] logging.py:143 >> {'loss': 0.4566, 'learning_rate': 2.2134e-05, 'epoch': 10.65, 'throughput': 3339.61}

[INFO|2025-05-14 20:34:06] logging.py:143 >> {'loss': 0.4669, 'learning_rate': 2.1953e-05, 'epoch': 10.69, 'throughput': 3339.49}

[INFO|2025-05-14 20:34:13] logging.py:143 >> {'loss': 0.4360, 'learning_rate': 2.1773e-05, 'epoch': 10.74, 'throughput': 3339.21}

[INFO|2025-05-14 20:34:20] logging.py:143 >> {'loss': 0.4300, 'learning_rate': 2.1593e-05, 'epoch': 10.79, 'throughput': 3339.30}

[INFO|2025-05-14 20:34:27] logging.py:143 >> {'loss': 0.4517, 'learning_rate': 2.1413e-05, 'epoch': 10.83, 'throughput': 3339.72}

[INFO|2025-05-14 20:34:34] logging.py:143 >> {'loss': 0.4590, 'learning_rate': 2.1233e-05, 'epoch': 10.88, 'throughput': 3339.66}

[INFO|2025-05-14 20:34:40] logging.py:143 >> {'loss': 0.4566, 'learning_rate': 2.1053e-05, 'epoch': 10.92, 'throughput': 3339.57}

[INFO|2025-05-14 20:34:47] logging.py:143 >> {'loss': 0.4559, 'learning_rate': 2.0874e-05, 'epoch': 10.97, 'throughput': 3339.92}

[INFO|2025-05-14 20:34:53] logging.py:143 >> {'loss': 0.4357, 'learning_rate': 2.0695e-05, 'epoch': 11.01, 'throughput': 3340.04}

[INFO|2025-05-14 20:35:00] logging.py:143 >> {'loss': 0.3996, 'learning_rate': 2.0516e-05, 'epoch': 11.06, 'throughput': 3340.05}

[INFO|2025-05-14 20:35:07] logging.py:143 >> {'loss': 0.3720, 'learning_rate': 2.0337e-05, 'epoch': 11.10, 'throughput': 3339.59}

[INFO|2025-05-14 20:35:13] logging.py:143 >> {'loss': 0.3863, 'learning_rate': 2.0158e-05, 'epoch': 11.15, 'throughput': 3339.82}

[INFO|2025-05-14 20:35:20] logging.py:143 >> {'loss': 0.3897, 'learning_rate': 1.9980e-05, 'epoch': 11.19, 'throughput': 3339.63}

[INFO|2025-05-14 20:35:27] logging.py:143 >> {'loss': 0.4100, 'learning_rate': 1.9802e-05, 'epoch': 11.24, 'throughput': 3339.72}

[INFO|2025-05-14 20:35:34] logging.py:143 >> {'loss': 0.4262, 'learning_rate': 1.9625e-05, 'epoch': 11.29, 'throughput': 3340.28}

[INFO|2025-05-14 20:35:41] logging.py:143 >> {'loss': 0.3974, 'learning_rate': 1.9447e-05, 'epoch': 11.33, 'throughput': 3340.56}

[INFO|2025-05-14 20:35:48] logging.py:143 >> {'loss': 0.4160, 'learning_rate': 1.9270e-05, 'epoch': 11.38, 'throughput': 3340.78}

[INFO|2025-05-14 20:35:54] logging.py:143 >> {'loss': 0.3974, 'learning_rate': 1.9093e-05, 'epoch': 11.43, 'throughput': 3340.73}

[INFO|2025-05-14 20:36:01] logging.py:143 >> {'loss': 0.4174, 'learning_rate': 1.8917e-05, 'epoch': 11.47, 'throughput': 3341.65}

[INFO|2025-05-14 20:36:08] logging.py:143 >> {'loss': 0.4072, 'learning_rate': 1.8740e-05, 'epoch': 11.52, 'throughput': 3341.93}

[INFO|2025-05-14 20:36:15] logging.py:143 >> {'loss': 0.3947, 'learning_rate': 1.8565e-05, 'epoch': 11.56, 'throughput': 3342.07}

[INFO|2025-05-14 20:36:22] logging.py:143 >> {'loss': 0.4077, 'learning_rate': 1.8389e-05, 'epoch': 11.61, 'throughput': 3342.24}

[INFO|2025-05-14 20:36:28] logging.py:143 >> {'loss': 0.4180, 'learning_rate': 1.8214e-05, 'epoch': 11.66, 'throughput': 3342.38}

[INFO|2025-05-14 20:36:35] logging.py:143 >> {'loss': 0.4168, 'learning_rate': 1.8039e-05, 'epoch': 11.70, 'throughput': 3342.69}

[INFO|2025-05-14 20:36:42] logging.py:143 >> {'loss': 0.4113, 'learning_rate': 1.7865e-05, 'epoch': 11.75, 'throughput': 3342.63}

[INFO|2025-05-14 20:36:49] logging.py:143 >> {'loss': 0.4170, 'learning_rate': 1.7691e-05, 'epoch': 11.80, 'throughput': 3342.60}

[INFO|2025-05-14 20:36:56] logging.py:143 >> {'loss': 0.4172, 'learning_rate': 1.7517e-05, 'epoch': 11.84, 'throughput': 3342.28}

[INFO|2025-05-14 20:37:03] logging.py:143 >> {'loss': 0.4207, 'learning_rate': 1.7344e-05, 'epoch': 11.89, 'throughput': 3342.07}

[INFO|2025-05-14 20:37:10] logging.py:143 >> {'loss': 0.3962, 'learning_rate': 1.7171e-05, 'epoch': 11.93, 'throughput': 3342.01}

[INFO|2025-05-14 20:37:17] logging.py:143 >> {'loss': 0.4364, 'learning_rate': 1.6998e-05, 'epoch': 11.98, 'throughput': 3342.84}

[INFO|2025-05-14 20:37:23] logging.py:143 >> {'loss': 0.3475, 'learning_rate': 1.6826e-05, 'epoch': 12.02, 'throughput': 3342.35}

[INFO|2025-05-14 20:37:30] logging.py:143 >> {'loss': 0.3574, 'learning_rate': 1.6655e-05, 'epoch': 12.06, 'throughput': 3342.02}

[INFO|2025-05-14 20:37:37] logging.py:143 >> {'loss': 0.3466, 'learning_rate': 1.6484e-05, 'epoch': 12.11, 'throughput': 3341.52}

[INFO|2025-05-14 20:37:43] logging.py:143 >> {'loss': 0.3273, 'learning_rate': 1.6313e-05, 'epoch': 12.16, 'throughput': 3341.87}

[INFO|2025-05-14 20:37:50] logging.py:143 >> {'loss': 0.3841, 'learning_rate': 1.6143e-05, 'epoch': 12.20, 'throughput': 3341.78}

[INFO|2025-05-14 20:37:57] logging.py:143 >> {'loss': 0.3557, 'learning_rate': 1.5973e-05, 'epoch': 12.25, 'throughput': 3341.87}

[INFO|2025-05-14 20:38:04] logging.py:143 >> {'loss': 0.3697, 'learning_rate': 1.5804e-05, 'epoch': 12.30, 'throughput': 3342.01}

[INFO|2025-05-14 20:38:11] logging.py:143 >> {'loss': 0.3634, 'learning_rate': 1.5635e-05, 'epoch': 12.34, 'throughput': 3341.87}

[INFO|2025-05-14 20:38:18] logging.py:143 >> {'loss': 0.3745, 'learning_rate': 1.5467e-05, 'epoch': 12.39, 'throughput': 3341.92}

[INFO|2025-05-14 20:38:25] logging.py:143 >> {'loss': 0.3498, 'learning_rate': 1.5299e-05, 'epoch': 12.43, 'throughput': 3342.14}

[INFO|2025-05-14 20:38:32] logging.py:143 >> {'loss': 0.3638, 'learning_rate': 1.5131e-05, 'epoch': 12.48, 'throughput': 3342.25}

[INFO|2025-05-14 20:38:39] logging.py:143 >> {'loss': 0.3868, 'learning_rate': 1.4965e-05, 'epoch': 12.53, 'throughput': 3342.50}

[INFO|2025-05-14 20:38:46] logging.py:143 >> {'loss': 0.3931, 'learning_rate': 1.4798e-05, 'epoch': 12.57, 'throughput': 3343.28}

[INFO|2025-05-14 20:38:52] logging.py:143 >> {'loss': 0.3727, 'learning_rate': 1.4633e-05, 'epoch': 12.62, 'throughput': 3343.59}

[INFO|2025-05-14 20:38:59] logging.py:143 >> {'loss': 0.3610, 'learning_rate': 1.4468e-05, 'epoch': 12.67, 'throughput': 3343.80}

[INFO|2025-05-14 20:39:06] logging.py:143 >> {'loss': 0.3537, 'learning_rate': 1.4303e-05, 'epoch': 12.71, 'throughput': 3343.68}

[INFO|2025-05-14 20:39:13] logging.py:143 >> {'loss': 0.3666, 'learning_rate': 1.4139e-05, 'epoch': 12.76, 'throughput': 3343.64}

[INFO|2025-05-14 20:39:20] logging.py:143 >> {'loss': 0.3411, 'learning_rate': 1.3975e-05, 'epoch': 12.80, 'throughput': 3343.44}

[INFO|2025-05-14 20:39:27] logging.py:143 >> {'loss': 0.3679, 'learning_rate': 1.3813e-05, 'epoch': 12.85, 'throughput': 3343.54}

[INFO|2025-05-14 20:39:34] logging.py:143 >> {'loss': 0.3437, 'learning_rate': 1.3650e-05, 'epoch': 12.90, 'throughput': 3343.06}

[INFO|2025-05-14 20:39:41] logging.py:143 >> {'loss': 0.3945, 'learning_rate': 1.3489e-05, 'epoch': 12.94, 'throughput': 3342.49}

[INFO|2025-05-14 20:39:48] logging.py:143 >> {'loss': 0.3856, 'learning_rate': 1.3327e-05, 'epoch': 12.99, 'throughput': 3342.36}

[INFO|2025-05-14 20:39:53] logging.py:143 >> {'loss': 0.3392, 'learning_rate': 1.3167e-05, 'epoch': 13.03, 'throughput': 3342.13}

[INFO|2025-05-14 20:40:00] logging.py:143 >> {'loss': 0.3153, 'learning_rate': 1.3007e-05, 'epoch': 13.07, 'throughput': 3341.86}

[INFO|2025-05-14 20:40:07] logging.py:143 >> {'loss': 0.3398, 'learning_rate': 1.2848e-05, 'epoch': 13.12, 'throughput': 3342.06}

[INFO|2025-05-14 20:40:14] logging.py:143 >> {'loss': 0.3246, 'learning_rate': 1.2689e-05, 'epoch': 13.17, 'throughput': 3342.08}

[INFO|2025-05-14 20:40:21] logging.py:143 >> {'loss': 0.3049, 'learning_rate': 1.2532e-05, 'epoch': 13.21, 'throughput': 3342.12}

[INFO|2025-05-14 20:40:28] logging.py:143 >> {'loss': 0.3265, 'learning_rate': 1.2374e-05, 'epoch': 13.26, 'throughput': 3342.02}

[INFO|2025-05-14 20:40:35] logging.py:143 >> {'loss': 0.3350, 'learning_rate': 1.2218e-05, 'epoch': 13.31, 'throughput': 3341.69}

[INFO|2025-05-14 20:40:42] logging.py:143 >> {'loss': 0.3239, 'learning_rate': 1.2062e-05, 'epoch': 13.35, 'throughput': 3342.02}

[INFO|2025-05-14 20:40:49] logging.py:143 >> {'loss': 0.2989, 'learning_rate': 1.1907e-05, 'epoch': 13.40, 'throughput': 3342.11}

[INFO|2025-05-14 20:40:56] logging.py:143 >> {'loss': 0.3170, 'learning_rate': 1.1752e-05, 'epoch': 13.44, 'throughput': 3342.32}

[INFO|2025-05-14 20:41:03] logging.py:143 >> {'loss': 0.3177, 'learning_rate': 1.1598e-05, 'epoch': 13.49, 'throughput': 3342.77}

[INFO|2025-05-14 20:41:10] logging.py:143 >> {'loss': 0.3454, 'learning_rate': 1.1445e-05, 'epoch': 13.54, 'throughput': 3342.39}

[INFO|2025-05-14 20:41:17] logging.py:143 >> {'loss': 0.3325, 'learning_rate': 1.1293e-05, 'epoch': 13.58, 'throughput': 3341.85}

[INFO|2025-05-14 20:41:24] logging.py:143 >> {'loss': 0.3407, 'learning_rate': 1.1141e-05, 'epoch': 13.63, 'throughput': 3341.94}

[INFO|2025-05-14 20:41:31] logging.py:143 >> {'loss': 0.3340, 'learning_rate': 1.0990e-05, 'epoch': 13.68, 'throughput': 3341.70}

[INFO|2025-05-14 20:41:38] logging.py:143 >> {'loss': 0.3417, 'learning_rate': 1.0840e-05, 'epoch': 13.72, 'throughput': 3341.27}

[INFO|2025-05-14 20:41:45] logging.py:143 >> {'loss': 0.3334, 'learning_rate': 1.0690e-05, 'epoch': 13.77, 'throughput': 3340.91}

[INFO|2025-05-14 20:41:52] logging.py:143 >> {'loss': 0.3469, 'learning_rate': 1.0542e-05, 'epoch': 13.81, 'throughput': 3341.04}

[INFO|2025-05-14 20:41:59] logging.py:143 >> {'loss': 0.3185, 'learning_rate': 1.0394e-05, 'epoch': 13.86, 'throughput': 3341.07}

[INFO|2025-05-14 20:42:05] logging.py:143 >> {'loss': 0.3293, 'learning_rate': 1.0247e-05, 'epoch': 13.91, 'throughput': 3341.27}

[INFO|2025-05-14 20:42:12] logging.py:143 >> {'loss': 0.3688, 'learning_rate': 1.0100e-05, 'epoch': 13.95, 'throughput': 3341.12}

[INFO|2025-05-14 20:42:19] logging.py:143 >> {'loss': 0.3520, 'learning_rate': 9.9546e-06, 'epoch': 14.00, 'throughput': 3340.89}

[INFO|2025-05-14 20:42:25] logging.py:143 >> {'loss': 0.2861, 'learning_rate': 9.8098e-06, 'epoch': 14.04, 'throughput': 3340.52}

[INFO|2025-05-14 20:42:32] logging.py:143 >> {'loss': 0.2922, 'learning_rate': 9.6658e-06, 'epoch': 14.08, 'throughput': 3340.61}

[INFO|2025-05-14 20:42:39] logging.py:143 >> {'loss': 0.2906, 'learning_rate': 9.5227e-06, 'epoch': 14.13, 'throughput': 3340.90}

[INFO|2025-05-14 20:42:46] logging.py:143 >> {'loss': 0.2744, 'learning_rate': 9.3803e-06, 'epoch': 14.18, 'throughput': 3340.79}

[INFO|2025-05-14 20:42:53] logging.py:143 >> {'loss': 0.2983, 'learning_rate': 9.2387e-06, 'epoch': 14.22, 'throughput': 3340.69}

[INFO|2025-05-14 20:43:00] logging.py:143 >> {'loss': 0.3122, 'learning_rate': 9.0980e-06, 'epoch': 14.27, 'throughput': 3340.74}

[INFO|2025-05-14 20:43:06] logging.py:143 >> {'loss': 0.2937, 'learning_rate': 8.9582e-06, 'epoch': 14.31, 'throughput': 3340.81}

[INFO|2025-05-14 20:43:13] logging.py:143 >> {'loss': 0.3068, 'learning_rate': 8.8192e-06, 'epoch': 14.36, 'throughput': 3340.80}

[INFO|2025-05-14 20:43:20] logging.py:143 >> {'loss': 0.3257, 'learning_rate': 8.6810e-06, 'epoch': 14.41, 'throughput': 3341.15}

[INFO|2025-05-14 20:43:27] logging.py:143 >> {'loss': 0.3111, 'learning_rate': 8.5437e-06, 'epoch': 14.45, 'throughput': 3341.04}

[INFO|2025-05-14 20:43:34] logging.py:143 >> {'loss': 0.2768, 'learning_rate': 8.4073e-06, 'epoch': 14.50, 'throughput': 3341.06}

[INFO|2025-05-14 20:43:41] logging.py:143 >> {'loss': 0.2956, 'learning_rate': 8.2717e-06, 'epoch': 14.55, 'throughput': 3340.93}

[INFO|2025-05-14 20:43:48] logging.py:143 >> {'loss': 0.3029, 'learning_rate': 8.1371e-06, 'epoch': 14.59, 'throughput': 3340.65}

[INFO|2025-05-14 20:43:55] logging.py:143 >> {'loss': 0.3287, 'learning_rate': 8.0033e-06, 'epoch': 14.64, 'throughput': 3340.74}

[INFO|2025-05-14 20:44:02] logging.py:143 >> {'loss': 0.3210, 'learning_rate': 7.8704e-06, 'epoch': 14.68, 'throughput': 3340.47}

[INFO|2025-05-14 20:44:09] logging.py:143 >> {'loss': 0.3053, 'learning_rate': 7.7385e-06, 'epoch': 14.73, 'throughput': 3340.25}

[INFO|2025-05-14 20:44:16] logging.py:143 >> {'loss': 0.2788, 'learning_rate': 7.6074e-06, 'epoch': 14.78, 'throughput': 3339.96}

[INFO|2025-05-14 20:44:23] logging.py:143 >> {'loss': 0.2941, 'learning_rate': 7.4773e-06, 'epoch': 14.82, 'throughput': 3339.99}

[INFO|2025-05-14 20:44:30] logging.py:143 >> {'loss': 0.2974, 'learning_rate': 7.3481e-06, 'epoch': 14.87, 'throughput': 3339.47}

[INFO|2025-05-14 20:44:37] logging.py:143 >> {'loss': 0.3036, 'learning_rate': 7.2198e-06, 'epoch': 14.92, 'throughput': 3339.44}

[INFO|2025-05-14 20:44:44] logging.py:143 >> {'loss': 0.3123, 'learning_rate': 7.0925e-06, 'epoch': 14.96, 'throughput': 3339.66}

[INFO|2025-05-14 20:44:50] logging.py:143 >> {'loss': 0.3253, 'learning_rate': 6.9661e-06, 'epoch': 15.00, 'throughput': 3339.56}

[INFO|2025-05-14 20:44:57] logging.py:143 >> {'loss': 0.2797, 'learning_rate': 6.8406e-06, 'epoch': 15.05, 'throughput': 3339.44}

[INFO|2025-05-14 20:45:04] logging.py:143 >> {'loss': 0.2717, 'learning_rate': 6.7162e-06, 'epoch': 15.09, 'throughput': 3339.23}

[INFO|2025-05-14 20:45:11] logging.py:143 >> {'loss': 0.2644, 'learning_rate': 6.5927e-06, 'epoch': 15.14, 'throughput': 3339.28}

[INFO|2025-05-14 20:45:18] logging.py:143 >> {'loss': 0.2553, 'learning_rate': 6.4701e-06, 'epoch': 15.18, 'throughput': 3338.29}

[INFO|2025-05-14 20:45:25] logging.py:143 >> {'loss': 0.2698, 'learning_rate': 6.3486e-06, 'epoch': 15.23, 'throughput': 3337.92}

[INFO|2025-05-14 20:45:32] logging.py:143 >> {'loss': 0.2691, 'learning_rate': 6.2280e-06, 'epoch': 15.28, 'throughput': 3337.85}

[INFO|2025-05-14 20:45:39] logging.py:143 >> {'loss': 0.2925, 'learning_rate': 6.1084e-06, 'epoch': 15.32, 'throughput': 3337.58}

[INFO|2025-05-14 20:45:46] logging.py:143 >> {'loss': 0.2803, 'learning_rate': 5.9899e-06, 'epoch': 15.37, 'throughput': 3337.84}

[INFO|2025-05-14 20:45:53] logging.py:143 >> {'loss': 0.2963, 'learning_rate': 5.8723e-06, 'epoch': 15.42, 'throughput': 3337.91}

[INFO|2025-05-14 20:46:00] logging.py:143 >> {'loss': 0.2744, 'learning_rate': 5.7557e-06, 'epoch': 15.46, 'throughput': 3338.42}

[INFO|2025-05-14 20:46:07] logging.py:143 >> {'loss': 0.2655, 'learning_rate': 5.6402e-06, 'epoch': 15.51, 'throughput': 3338.01}

[INFO|2025-05-14 20:46:14] logging.py:143 >> {'loss': 0.2520, 'learning_rate': 5.5257e-06, 'epoch': 15.55, 'throughput': 3337.94}

[INFO|2025-05-14 20:46:21] logging.py:143 >> {'loss': 0.2797, 'learning_rate': 5.4122e-06, 'epoch': 15.60, 'throughput': 3337.74}

[INFO|2025-05-14 20:46:28] logging.py:143 >> {'loss': 0.2886, 'learning_rate': 5.2997e-06, 'epoch': 15.65, 'throughput': 3337.70}

[INFO|2025-05-14 20:46:35] logging.py:143 >> {'loss': 0.2685, 'learning_rate': 5.1883e-06, 'epoch': 15.69, 'throughput': 3337.47}

[INFO|2025-05-14 20:46:42] logging.py:143 >> {'loss': 0.2889, 'learning_rate': 5.0780e-06, 'epoch': 15.74, 'throughput': 3337.38}

[INFO|2025-05-14 20:46:49] logging.py:143 >> {'loss': 0.2818, 'learning_rate': 4.9687e-06, 'epoch': 15.79, 'throughput': 3337.07}

[INFO|2025-05-14 20:46:56] logging.py:143 >> {'loss': 0.2995, 'learning_rate': 4.8604e-06, 'epoch': 15.83, 'throughput': 3337.51}

[INFO|2025-05-14 20:47:03] logging.py:143 >> {'loss': 0.2952, 'learning_rate': 4.7532e-06, 'epoch': 15.88, 'throughput': 3337.78}

[INFO|2025-05-14 20:47:09] logging.py:143 >> {'loss': 0.2884, 'learning_rate': 4.6471e-06, 'epoch': 15.92, 'throughput': 3337.92}

[INFO|2025-05-14 20:47:16] logging.py:143 >> {'loss': 0.2992, 'learning_rate': 4.5421e-06, 'epoch': 15.97, 'throughput': 3338.07}

[INFO|2025-05-14 20:47:22] logging.py:143 >> {'loss': 0.2726, 'learning_rate': 4.4381e-06, 'epoch': 16.01, 'throughput': 3338.36}

[INFO|2025-05-14 20:47:29] logging.py:143 >> {'loss': 0.2813, 'learning_rate': 4.3353e-06, 'epoch': 16.06, 'throughput': 3338.31}

[INFO|2025-05-14 20:47:36] logging.py:143 >> {'loss': 0.2567, 'learning_rate': 4.2335e-06, 'epoch': 16.10, 'throughput': 3338.18}

[INFO|2025-05-14 20:47:43] logging.py:143 >> {'loss': 0.2433, 'learning_rate': 4.1328e-06, 'epoch': 16.15, 'throughput': 3338.16}

[INFO|2025-05-14 20:47:50] logging.py:143 >> {'loss': 0.2692, 'learning_rate': 4.0332e-06, 'epoch': 16.19, 'throughput': 3337.91}

[INFO|2025-05-14 20:47:57] logging.py:143 >> {'loss': 0.2680, 'learning_rate': 3.9348e-06, 'epoch': 16.24, 'throughput': 3338.12}

[INFO|2025-05-14 20:48:03] logging.py:143 >> {'loss': 0.2506, 'learning_rate': 3.8374e-06, 'epoch': 16.29, 'throughput': 3338.19}

[INFO|2025-05-14 20:48:10] logging.py:143 >> {'loss': 0.2640, 'learning_rate': 3.7412e-06, 'epoch': 16.33, 'throughput': 3337.98}

[INFO|2025-05-14 20:48:17] logging.py:143 >> {'loss': 0.2569, 'learning_rate': 3.6461e-06, 'epoch': 16.38, 'throughput': 3338.09}

[INFO|2025-05-14 20:48:24] logging.py:143 >> {'loss': 0.2858, 'learning_rate': 3.5521e-06, 'epoch': 16.43, 'throughput': 3338.08}

[INFO|2025-05-14 20:48:31] logging.py:143 >> {'loss': 0.2577, 'learning_rate': 3.4593e-06, 'epoch': 16.47, 'throughput': 3338.40}

[INFO|2025-05-14 20:48:38] logging.py:143 >> {'loss': 0.2632, 'learning_rate': 3.3676e-06, 'epoch': 16.52, 'throughput': 3338.50}

[INFO|2025-05-14 20:48:44] logging.py:143 >> {'loss': 0.2660, 'learning_rate': 3.2770e-06, 'epoch': 16.56, 'throughput': 3338.80}

[INFO|2025-05-14 20:48:51] logging.py:143 >> {'loss': 0.2448, 'learning_rate': 3.1876e-06, 'epoch': 16.61, 'throughput': 3338.87}

[INFO|2025-05-14 20:48:58] logging.py:143 >> {'loss': 0.2493, 'learning_rate': 3.0993e-06, 'epoch': 16.66, 'throughput': 3338.85}

[INFO|2025-05-14 20:49:05] logging.py:143 >> {'loss': 0.2714, 'learning_rate': 3.0122e-06, 'epoch': 16.70, 'throughput': 3338.91}

[INFO|2025-05-14 20:49:12] logging.py:143 >> {'loss': 0.2871, 'learning_rate': 2.9263e-06, 'epoch': 16.75, 'throughput': 3339.09}

[INFO|2025-05-14 20:49:19] logging.py:143 >> {'loss': 0.2826, 'learning_rate': 2.8415e-06, 'epoch': 16.80, 'throughput': 3339.43}

[INFO|2025-05-14 20:49:26] logging.py:143 >> {'loss': 0.2588, 'learning_rate': 2.7579e-06, 'epoch': 16.84, 'throughput': 3339.38}

[INFO|2025-05-14 20:49:33] logging.py:143 >> {'loss': 0.2625, 'learning_rate': 2.6755e-06, 'epoch': 16.89, 'throughput': 3339.40}

[INFO|2025-05-14 20:49:40] logging.py:143 >> {'loss': 0.2694, 'learning_rate': 2.5943e-06, 'epoch': 16.93, 'throughput': 3339.20}

[INFO|2025-05-14 20:49:47] logging.py:143 >> {'loss': 0.2541, 'learning_rate': 2.5142e-06, 'epoch': 16.98, 'throughput': 3338.91}

[INFO|2025-05-14 20:49:53] logging.py:143 >> {'loss': 0.2769, 'learning_rate': 2.4354e-06, 'epoch': 17.02, 'throughput': 3338.63}

[INFO|2025-05-14 20:49:59] logging.py:143 >> {'loss': 0.2455, 'learning_rate': 2.3577e-06, 'epoch': 17.06, 'throughput': 3338.65}

[INFO|2025-05-14 20:50:06] logging.py:143 >> {'loss': 0.2508, 'learning_rate': 2.2812e-06, 'epoch': 17.11, 'throughput': 3338.81}

[INFO|2025-05-14 20:50:13] logging.py:143 >> {'loss': 0.2414, 'learning_rate': 2.2059e-06, 'epoch': 17.16, 'throughput': 3338.69}

[INFO|2025-05-14 20:50:20] logging.py:143 >> {'loss': 0.2447, 'learning_rate': 2.1319e-06, 'epoch': 17.20, 'throughput': 3338.58}

[INFO|2025-05-14 20:50:27] logging.py:143 >> {'loss': 0.2728, 'learning_rate': 2.0590e-06, 'epoch': 17.25, 'throughput': 3338.85}

[INFO|2025-05-14 20:50:34] logging.py:143 >> {'loss': 0.2462, 'learning_rate': 1.9874e-06, 'epoch': 17.30, 'throughput': 3338.59}

[INFO|2025-05-14 20:50:41] logging.py:143 >> {'loss': 0.2693, 'learning_rate': 1.9170e-06, 'epoch': 17.34, 'throughput': 3339.10}

[INFO|2025-05-14 20:50:48] logging.py:143 >> {'loss': 0.2678, 'learning_rate': 1.8477e-06, 'epoch': 17.39, 'throughput': 3339.15}

[INFO|2025-05-14 20:50:55] logging.py:143 >> {'loss': 0.2503, 'learning_rate': 1.7798e-06, 'epoch': 17.43, 'throughput': 3339.42}

[INFO|2025-05-14 20:51:02] logging.py:143 >> {'loss': 0.2489, 'learning_rate': 1.7130e-06, 'epoch': 17.48, 'throughput': 3339.44}

[INFO|2025-05-14 20:51:09] logging.py:143 >> {'loss': 0.2462, 'learning_rate': 1.6475e-06, 'epoch': 17.53, 'throughput': 3338.87}

[INFO|2025-05-14 20:51:16] logging.py:143 >> {'loss': 0.2527, 'learning_rate': 1.5832e-06, 'epoch': 17.57, 'throughput': 3338.49}

[INFO|2025-05-14 20:51:23] logging.py:143 >> {'loss': 0.2595, 'learning_rate': 1.5201e-06, 'epoch': 17.62, 'throughput': 3338.21}

[INFO|2025-05-14 20:51:30] logging.py:143 >> {'loss': 0.2512, 'learning_rate': 1.4583e-06, 'epoch': 17.67, 'throughput': 3337.99}

[INFO|2025-05-14 20:51:37] logging.py:143 >> {'loss': 0.2492, 'learning_rate': 1.3978e-06, 'epoch': 17.71, 'throughput': 3337.73}

[INFO|2025-05-14 20:51:44] logging.py:143 >> {'loss': 0.2571, 'learning_rate': 1.3385e-06, 'epoch': 17.76, 'throughput': 3337.65}

[INFO|2025-05-14 20:51:51] logging.py:143 >> {'loss': 0.2570, 'learning_rate': 1.2804e-06, 'epoch': 17.80, 'throughput': 3337.54}

[INFO|2025-05-14 20:51:58] logging.py:143 >> {'loss': 0.2490, 'learning_rate': 1.2236e-06, 'epoch': 17.85, 'throughput': 3337.53}

[INFO|2025-05-14 20:52:05] logging.py:143 >> {'loss': 0.2468, 'learning_rate': 1.1680e-06, 'epoch': 17.90, 'throughput': 3337.38}

[INFO|2025-05-14 20:52:12] logging.py:143 >> {'loss': 0.2760, 'learning_rate': 1.1137e-06, 'epoch': 17.94, 'throughput': 3337.22}

[INFO|2025-05-14 20:52:19] logging.py:143 >> {'loss': 0.2573, 'learning_rate': 1.0607e-06, 'epoch': 17.99, 'throughput': 3337.20}

[INFO|2025-05-14 20:52:24] logging.py:143 >> {'loss': 0.2195, 'learning_rate': 1.0090e-06, 'epoch': 18.03, 'throughput': 3337.04}

[INFO|2025-05-14 20:52:31] logging.py:143 >> {'loss': 0.2486, 'learning_rate': 9.5846e-07, 'epoch': 18.07, 'throughput': 3337.15}

[INFO|2025-05-14 20:52:38] logging.py:143 >> {'loss': 0.2558, 'learning_rate': 9.0924e-07, 'epoch': 18.12, 'throughput': 3337.26}

[INFO|2025-05-14 20:52:45] logging.py:143 >> {'loss': 0.2567, 'learning_rate': 8.6129e-07, 'epoch': 18.17, 'throughput': 3337.22}

[INFO|2025-05-14 20:52:52] logging.py:143 >> {'loss': 0.2439, 'learning_rate': 8.1462e-07, 'epoch': 18.21, 'throughput': 3337.21}

[INFO|2025-05-14 20:52:59] logging.py:143 >> {'loss': 0.2508, 'learning_rate': 7.6923e-07, 'epoch': 18.26, 'throughput': 3337.24}

[INFO|2025-05-14 20:53:06] logging.py:143 >> {'loss': 0.2629, 'learning_rate': 7.2512e-07, 'epoch': 18.31, 'throughput': 3337.01}

[INFO|2025-05-14 20:53:13] logging.py:143 >> {'loss': 0.2664, 'learning_rate': 6.8229e-07, 'epoch': 18.35, 'throughput': 3337.30}

[INFO|2025-05-14 20:53:20] logging.py:143 >> {'loss': 0.2538, 'learning_rate': 6.4075e-07, 'epoch': 18.40, 'throughput': 3337.44}

[INFO|2025-05-14 20:53:26] logging.py:143 >> {'loss': 0.2472, 'learning_rate': 6.0050e-07, 'epoch': 18.44, 'throughput': 3337.56}

[INFO|2025-05-14 20:53:33] logging.py:143 >> {'loss': 0.2407, 'learning_rate': 5.6153e-07, 'epoch': 18.49, 'throughput': 3337.67}

[INFO|2025-05-14 20:53:40] logging.py:143 >> {'loss': 0.2567, 'learning_rate': 5.2386e-07, 'epoch': 18.54, 'throughput': 3337.87}

[INFO|2025-05-14 20:53:47] logging.py:143 >> {'loss': 0.2452, 'learning_rate': 4.8749e-07, 'epoch': 18.58, 'throughput': 3338.24}

[INFO|2025-05-14 20:53:54] logging.py:143 >> {'loss': 0.2373, 'learning_rate': 4.5241e-07, 'epoch': 18.63, 'throughput': 3338.20}

[INFO|2025-05-14 20:54:01] logging.py:143 >> {'loss': 0.2495, 'learning_rate': 4.1863e-07, 'epoch': 18.68, 'throughput': 3338.09}

[INFO|2025-05-14 20:54:07] logging.py:143 >> {'loss': 0.2518, 'learning_rate': 3.8615e-07, 'epoch': 18.72, 'throughput': 3337.94}

[INFO|2025-05-14 20:54:14] logging.py:143 >> {'loss': 0.2398, 'learning_rate': 3.5497e-07, 'epoch': 18.77, 'throughput': 3338.13}

[INFO|2025-05-14 20:54:21] logging.py:143 >> {'loss': 0.2432, 'learning_rate': 3.2509e-07, 'epoch': 18.81, 'throughput': 3338.18}

[INFO|2025-05-14 20:54:28] logging.py:143 >> {'loss': 0.2466, 'learning_rate': 2.9652e-07, 'epoch': 18.86, 'throughput': 3338.10}

[INFO|2025-05-14 20:54:35] logging.py:143 >> {'loss': 0.2444, 'learning_rate': 2.6926e-07, 'epoch': 18.91, 'throughput': 3338.35}

[INFO|2025-05-14 20:54:42] logging.py:143 >> {'loss': 0.2425, 'learning_rate': 2.4330e-07, 'epoch': 18.95, 'throughput': 3338.45}

[INFO|2025-05-14 20:54:48] logging.py:143 >> {'loss': 0.2256, 'learning_rate': 2.1865e-07, 'epoch': 19.00, 'throughput': 3338.65}

[INFO|2025-05-14 20:54:54] logging.py:143 >> {'loss': 0.2543, 'learning_rate': 1.9531e-07, 'epoch': 19.04, 'throughput': 3338.56}

[INFO|2025-05-14 20:55:01] logging.py:143 >> {'loss': 0.2573, 'learning_rate': 1.7329e-07, 'epoch': 19.08, 'throughput': 3338.78}

[INFO|2025-05-14 20:55:08] logging.py:143 >> {'loss': 0.2349, 'learning_rate': 1.5258e-07, 'epoch': 19.13, 'throughput': 3338.84}

[INFO|2025-05-14 20:55:15] logging.py:143 >> {'loss': 0.2312, 'learning_rate': 1.3318e-07, 'epoch': 19.18, 'throughput': 3338.76}

[INFO|2025-05-14 20:55:21] logging.py:143 >> {'loss': 0.2620, 'learning_rate': 1.1510e-07, 'epoch': 19.22, 'throughput': 3339.08}

[INFO|2025-05-14 20:55:28] logging.py:143 >> {'loss': 0.2250, 'learning_rate': 9.8328e-08, 'epoch': 19.27, 'throughput': 3339.36}

[INFO|2025-05-14 20:55:35] logging.py:143 >> {'loss': 0.2409, 'learning_rate': 8.2878e-08, 'epoch': 19.31, 'throughput': 3339.32}

[INFO|2025-05-14 20:55:42] logging.py:143 >> {'loss': 0.2382, 'learning_rate': 6.8745e-08, 'epoch': 19.36, 'throughput': 3339.48}

[INFO|2025-05-14 20:55:49] logging.py:143 >> {'loss': 0.2499, 'learning_rate': 5.5931e-08, 'epoch': 19.41, 'throughput': 3339.57}

[INFO|2025-05-14 20:55:55] logging.py:143 >> {'loss': 0.2459, 'learning_rate': 4.4437e-08, 'epoch': 19.45, 'throughput': 3339.63}

[INFO|2025-05-14 20:56:02] logging.py:143 >> {'loss': 0.2437, 'learning_rate': 3.4262e-08, 'epoch': 19.50, 'throughput': 3339.58}

[INFO|2025-05-14 20:56:09] logging.py:143 >> {'loss': 0.2388, 'learning_rate': 2.5407e-08, 'epoch': 19.55, 'throughput': 3339.73}

[INFO|2025-05-14 20:56:16] logging.py:143 >> {'loss': 0.2410, 'learning_rate': 1.7873e-08, 'epoch': 19.59, 'throughput': 3339.79}

[INFO|2025-05-14 20:56:23] logging.py:143 >> {'loss': 0.2632, 'learning_rate': 1.1660e-08, 'epoch': 19.64, 'throughput': 3339.64}

[INFO|2025-05-14 20:56:30] logging.py:143 >> {'loss': 0.2374, 'learning_rate': 6.7690e-09, 'epoch': 19.68, 'throughput': 3339.65}

[INFO|2025-05-14 20:56:37] logging.py:143 >> {'loss': 0.2530, 'learning_rate': 3.1995e-09, 'epoch': 19.73, 'throughput': 3339.99}

[INFO|2025-05-14 20:56:43] logging.py:143 >> {'loss': 0.2324, 'learning_rate': 9.5192e-10, 'epoch': 19.78, 'throughput': 3340.04}

[INFO|2025-05-14 20:56:50] logging.py:143 >> {'loss': 0.2334, 'learning_rate': 2.6442e-11, 'epoch': 19.82, 'throughput': 3340.26}

[INFO|2025-05-14 20:56:50] trainer.py:3984 >> Saving model checkpoint to saves/Qwen2.5-1.5B-Instruct/lora/train_2025-05-14-20-04-42/checkpoint-2160

[INFO|2025-05-14 20:56:50] configuration_utils.py:691 >> loading configuration file models/Qwen2_5-1_5b-Instruct/config.json

[INFO|2025-05-14 20:56:50] configuration_utils.py:765 >> Model config Qwen2Config {
  "architectures": [
    "Qwen2ForCausalLM"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151645,
  "hidden_act": "silu",
  "hidden_size": 1536,
  "initializer_range": 0.02,
  "intermediate_size": 8960,
  "max_position_embeddings": 32768,
  "max_window_layers": 21,
  "model_type": "qwen2",
  "num_attention_heads": 12,
  "num_hidden_layers": 28,
  "num_key_value_heads": 2,
  "rms_norm_eps": 1e-06,
  "rope_scaling": null,
  "rope_theta": 1000000.0,
  "sliding_window": 32768,
  "tie_word_embeddings": true,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.51.3",
  "use_cache": true,
  "use_sliding_window": false,
  "vocab_size": 151936
}


[INFO|2025-05-14 20:56:50] tokenization_utils_base.py:2510 >> tokenizer config file saved in saves/Qwen2.5-1.5B-Instruct/lora/train_2025-05-14-20-04-42/checkpoint-2160/tokenizer_config.json

[INFO|2025-05-14 20:56:50] tokenization_utils_base.py:2519 >> Special tokens file saved in saves/Qwen2.5-1.5B-Instruct/lora/train_2025-05-14-20-04-42/checkpoint-2160/special_tokens_map.json

[INFO|2025-05-14 20:56:51] trainer.py:2681 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)



[INFO|2025-05-14 20:56:51] trainer.py:3984 >> Saving model checkpoint to saves/Qwen2.5-1.5B-Instruct/lora/train_2025-05-14-20-04-42

[INFO|2025-05-14 20:56:51] configuration_utils.py:691 >> loading configuration file models/Qwen2_5-1_5b-Instruct/config.json

[INFO|2025-05-14 20:56:51] configuration_utils.py:765 >> Model config Qwen2Config {
  "architectures": [
    "Qwen2ForCausalLM"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151645,
  "hidden_act": "silu",
  "hidden_size": 1536,
  "initializer_range": 0.02,
  "intermediate_size": 8960,
  "max_position_embeddings": 32768,
  "max_window_layers": 21,
  "model_type": "qwen2",
  "num_attention_heads": 12,
  "num_hidden_layers": 28,
  "num_key_value_heads": 2,
  "rms_norm_eps": 1e-06,
  "rope_scaling": null,
  "rope_theta": 1000000.0,
  "sliding_window": 32768,
  "tie_word_embeddings": true,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.51.3",
  "use_cache": true,
  "use_sliding_window": false,
  "vocab_size": 151936
}


[INFO|2025-05-14 20:56:51] tokenization_utils_base.py:2510 >> tokenizer config file saved in saves/Qwen2.5-1.5B-Instruct/lora/train_2025-05-14-20-04-42/tokenizer_config.json

[INFO|2025-05-14 20:56:51] tokenization_utils_base.py:2519 >> Special tokens file saved in saves/Qwen2.5-1.5B-Instruct/lora/train_2025-05-14-20-04-42/special_tokens_map.json

[WARNING|2025-05-14 20:56:51] logging.py:148 >> No metric eval_loss to plot.

[WARNING|2025-05-14 20:56:51] logging.py:148 >> No metric eval_accuracy to plot.

[INFO|2025-05-14 20:56:51] modelcard.py:450 >> Dropping the following result as it does not have all the necessary fields:
{'task': {'name': 'Causal Language Modeling', 'type': 'text-generation'}}

